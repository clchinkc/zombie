import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import (
    BatchNormalization,
    Conv2D,
    Dense,
    Flatten,
    Input,
    Reshape,
    Softmax,
)
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical


# Function to convert one-hot encoded data to single-channel format
def one_hot_to_single_channel(data):
    return np.argmax(data, axis=-1)

# Define the generator
def build_generator(latent_dim, data_shape):
    model = Sequential()
    model.add(Input(shape=(latent_dim,)))
    model.add(Dense(128, activation="elu"))
    model.add(BatchNormalization())
    model.add(Dense(np.prod(data_shape) * 4))  # Multiply by 4 for one-hot encoding
    model.add(Reshape((*data_shape, 4)))
    model.add(Softmax(axis=-1))
    return model

# Define the discriminator with input processing
def build_discriminator(data_shape):
    model = Sequential()
    model.add(Input(shape=(*data_shape, 4)))  # Shape includes one-hot depth
    model.add(Conv2D(128, kernel_size=(3, 3), padding='valid', activation="elu"))
    model.add(BatchNormalization())
    model.add(Conv2D(64, kernel_size=(3, 3), padding='valid', activation="elu"))
    model.add(BatchNormalization())
    model.add(Flatten())
    model.add(Dense(1, activation='sigmoid'))
    return model

# Define GAN
def build_gan(generator, discriminator):
    discriminator.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])
    discriminator.trainable = False

    gan_input = Input(shape=(latent_dim,))
    gan_output = discriminator(generator(gan_input))

    gan = Model(gan_input, gan_output)
    gan.compile(loss='binary_crossentropy', optimizer=Adam())

    return gan

# GAN training function
def train_gan(gan, generator, discriminator, latent_dim, epochs, batch_size, data_shape, 
              discriminator_interval=5, generator_interval=1):
    valid = np.ones((batch_size, 1))
    fake = np.zeros((batch_size, 1))

    for epoch in range(epochs):
        d_loss_total = np.zeros(2)
        g_loss_total = 0
        
        for _ in range(discriminator_interval):
            # Generate random noise as input for the generator
            noise = np.random.normal(0, 1, (batch_size, latent_dim))

            # Generate fake images
            gen_imgs = generator.predict(noise, verbose=0)

            # Generate real images (random one-hot encoded grids)
            real_imgs = to_categorical(np.random.randint(0, 4, (batch_size, *data_shape)), num_classes=4)

            # Train the discriminator
            discriminator.trainable = True
            d_loss_real = discriminator.train_on_batch(real_imgs, valid)
            d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)
            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)
            
            d_loss_total += np.array(d_loss)

        for _ in range(generator_interval):
            noise = np.random.normal(0, 1, (batch_size, latent_dim))

            # Train the generator (via the GAN model)
            discriminator.trainable = False
            g_loss = gan.train_on_batch(noise, valid)
            
            g_loss_total += g_loss

        # Calculate average losses
        d_loss_avg = d_loss_total / discriminator_interval
        g_loss_avg = g_loss_total / generator_interval

        # Print progress
        print(f"Epoch: {epoch} [D loss: {d_loss_avg[0]}, acc.: {d_loss_avg[1]}] [G loss: {g_loss_avg}]")

    # Generate a sample data after training
    sample_noise = np.random.normal(0, 1, (1, latent_dim))
    generated_data = generator.predict(sample_noise, verbose=0)
    generated_data_class = np.argmax(generated_data, axis=-1)
    print("Generated Data (class representation):")
    print(generated_data_class[0])

# Set dimensions and shapes
latent_dim = 100
data_shape = (10, 10)  # Shape of the data to be generated by the GAN

# Build and compile GAN
generator = build_generator(latent_dim, data_shape)
discriminator = build_discriminator(data_shape)
gan = build_gan(generator, discriminator)

# Train GAN
train_gan(gan, generator, discriminator, latent_dim, epochs=10, batch_size=16, data_shape=data_shape, discriminator_interval=2, generator_interval=1)
